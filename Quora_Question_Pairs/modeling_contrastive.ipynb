{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 23:49:40.851700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset import Collator, Dataset\n",
    "from metrics import compute_metrics_on_df_contrastive\n",
    "from model import MeanPooler, SiameseContrastiveBERT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "from train_contrastive import train\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from utils import chunks, set_global_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "config = {\n",
    "    'MODEL_NAME':        'distilroberta-base',\n",
    "    'BATCH_SIZE':        128,\n",
    "    'LEARNING_RATE':     1e-5,\n",
    "    'N_EPOCHS':          10,\n",
    "    'MARGIN':            2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "experiment_name = f\"MODEL_CONTRASTIVE_{config['MODEL_NAME']}_BATCH_{config['BATCH_SIZE']}_LR_{config['LEARNING_RATE']}_MARGIN_{config['MARGIN']}\"\n",
    "\n",
    "writer = SummaryWriter(\n",
    "    log_dir=f\"runs/{experiment_name}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv', index_col='id')\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "df['question1'] = df['question1'].str.lower()\n",
    "df['question2'] = df['question2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv('./data/test.csv', index_col='test_id')\n",
    "df_submission.fillna('', inplace=True)\n",
    "\n",
    "df_submission['question1'] = df_submission['question1'].str.lower()\n",
    "df_submission['question2'] = df_submission['question2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor (koh-i-noor) dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely? how can i solve...</td>\n",
       "      <td>find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>how many keywords are there in the racket prog...</td>\n",
       "      <td>how many keywords are there in perl programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>do you believe there is life after death?</td>\n",
       "      <td>is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>what is one coin?</td>\n",
       "      <td>what's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>what is the approx annual cost of living while...</td>\n",
       "      <td>i am having little hairfall problem but i want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>what is like to have sex with cousin?</td>\n",
       "      <td>what is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "id                                                                          \n",
       "0            1       2  what is the step by step guide to invest in sh...   \n",
       "1            3       4  what is the story of kohinoor (koh-i-noor) dia...   \n",
       "2            5       6  how can i increase the speed of my internet co...   \n",
       "3            7       8  why am i mentally very lonely? how can i solve...   \n",
       "4            9      10  which one dissolve in water quikly sugar, salt...   \n",
       "...        ...     ...                                                ...   \n",
       "404285  433578  379845  how many keywords are there in the racket prog...   \n",
       "404286   18840  155606          do you believe there is life after death?   \n",
       "404287  537928  537929                                  what is one coin?   \n",
       "404288  537930  537931  what is the approx annual cost of living while...   \n",
       "404289  537932  537933              what is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "id                                                                       \n",
       "0       what is the step by step guide to invest in sh...             0  \n",
       "1       what would happen if the indian government sto...             0  \n",
       "2       how can internet speed be increased by hacking...             0  \n",
       "3       find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  how many keywords are there in perl programmin...             0  \n",
       "404286         is it true that there is life after death?             1  \n",
       "404287                                  what's this coin?             0  \n",
       "404288  i am having little hairfall problem but i want...             0  \n",
       "404289      what is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how does the surface pro himself 4 compare wit...</td>\n",
       "      <td>why did microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>should i have a hair transplant at age 24? how...</td>\n",
       "      <td>how much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what but is the best way to send money from ch...</td>\n",
       "      <td>what you send money to china?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>which food not emulsifiers?</td>\n",
       "      <td>what foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how \"aberystwyth\" start reading?</td>\n",
       "      <td>how their can i start reading?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>how do peaks (tv series): why did leland kill ...</td>\n",
       "      <td>what is the most study scene in twin peaks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>what does be \"in transit\" mean on fedex tracking?</td>\n",
       "      <td>how question fedex packages delivered?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>what are some famous romanian drinks (alcoholi...</td>\n",
       "      <td>can a non-alcoholic restaurant be a huge success?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>what were the best and worst things about publ...</td>\n",
       "      <td>what are the best and worst things examination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>what is the best medication equation erectile ...</td>\n",
       "      <td>how do i out get rid of erectile dysfunction?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question1  \\\n",
       "test_id                                                      \n",
       "0        how does the surface pro himself 4 compare wit...   \n",
       "1        should i have a hair transplant at age 24? how...   \n",
       "2        what but is the best way to send money from ch...   \n",
       "3                              which food not emulsifiers?   \n",
       "4                         how \"aberystwyth\" start reading?   \n",
       "...                                                    ...   \n",
       "2345791  how do peaks (tv series): why did leland kill ...   \n",
       "2345792  what does be \"in transit\" mean on fedex tracking?   \n",
       "2345793  what are some famous romanian drinks (alcoholi...   \n",
       "2345794  what were the best and worst things about publ...   \n",
       "2345795  what is the best medication equation erectile ...   \n",
       "\n",
       "                                                 question2  \n",
       "test_id                                                     \n",
       "0        why did microsoft choose core m3 and not core ...  \n",
       "1              how much cost does hair transplant require?  \n",
       "2                            what you send money to china?  \n",
       "3                                        what foods fibre?  \n",
       "4                           how their can i start reading?  \n",
       "...                                                    ...  \n",
       "2345791        what is the most study scene in twin peaks?  \n",
       "2345792             how question fedex packages delivered?  \n",
       "2345793  can a non-alcoholic restaurant be a huge success?  \n",
       "2345794  what are the best and worst things examination...  \n",
       "2345795      how do i out get rid of erectile dysfunction?  \n",
       "\n",
       "[2345796 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255027\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=df['is_duplicate'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 303217\n",
      "Test size: 101073\n"
     ]
    }
   ],
   "source": [
    "print(f'Train size: {df_train.shape[0]}')\n",
    "print(f'Test size: {df_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(df=df_train)\n",
    "test_dataset = Dataset(df=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config['MODEL_NAME'])\n",
    "bert_model = AutoModel.from_pretrained(config['MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "    'return_tensors': 'pt',\n",
    "    'padding':        True,\n",
    "    'truncation':     True,\n",
    "    'max_length':     512,\n",
    "}\n",
    "\n",
    "collate_fn = Collator(tokenizer, tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler = MeanPooler()\n",
    "\n",
    "model = SiameseContrastiveBERT(\n",
    "    bert_model=bert_model,\n",
    "    pooler=pooler,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, margin: float):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor, tgt: torch.LongTensor) -> torch.Tensor:\n",
    "        euclidian_distance = torch.nn.functional.pairwise_distance(x1, x2)\n",
    "        \n",
    "        positive_pairs_loss = tgt * euclidian_distance\n",
    "        negative_pairs_loss = (1 - tgt) * torch.relu(self.margin - euclidian_distance)\n",
    "\n",
    "        return (positive_pairs_loss + negative_pairs_loss).mean()\n",
    "\n",
    "    \n",
    "criterion = ContrastiveLoss(margin=config['MARGIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 2369/2369 [17:05<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5440973055267092\n",
      "\n",
      "Train metrics:\n",
      "{'accuracy': 0.6310892858909626, 'precision': 0.967741935483871, 'recall': 0.0008039518700813778, 'f1': 0.0016065690824705464, 'roc_auc': 0.8956519850783511, 'log_loss': 5.606496789302467}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 790/790 [01:38<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.4183670246525656\n",
      "\n",
      "Test metrics:\n",
      "{'accuracy': 0.6318304591730729, 'precision': 0.9482758620689655, 'recall': 0.002947797191553221, 'f1': 0.005877324214575763, 'roc_auc': 0.9108382207397486, 'log_loss': 4.78596155847873}\n",
      "\n",
      "Epoch [2 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 2369/2369 [17:05<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.44650214005996025\n",
      "\n",
      "Train metrics:\n",
      "{'accuracy': 0.6436281606901988, 'precision': 0.9376547377897817, 'recall': 0.03721403878621133, 'f1': 0.07158690609158863, 'roc_auc': 0.9151327518922898, 'log_loss': 4.146628668694763}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 790/790 [01:37<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.40534631821173656\n",
      "\n",
      "Test metrics:\n",
      "{'accuracy': 0.6667656050577305, 'precision': 0.9393280154701474, 'recall': 0.10413763533068925, 'f1': 0.18748944587846478, 'roc_auc': 0.9086321018335889, 'log_loss': 3.6290640577155857}\n",
      "\n",
      "Epoch [3 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 2369/2369 [17:08<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.40917006958985236\n",
      "\n",
      "Train metrics:\n",
      "{'accuracy': 0.6870129313330058, 'precision': 0.9273392839233778, 'recall': 0.16519424370461022, 'f1': 0.28043278817793754, 'roc_auc': 0.924837822828506, 'log_loss': 3.6894847433261804}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 790/790 [01:38<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.369601476079301\n",
      "\n",
      "Test metrics:\n",
      "{'accuracy': 0.7023042751278779, 'precision': 0.9245682058512513, 'recall': 0.2108746918212027, 'f1': 0.34342200013092716, 'roc_auc': 0.9176680967764886, 'log_loss': 3.9701220194862787}\n",
      "\n",
      "Epoch [4 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches:  80%|███████▉  | 1895/2369 [13:37<03:24,  2.32it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loop over train batches: 100%|██████████| 2369/2369 [17:08<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3366064605719432\n",
      "\n",
      "Train metrics:\n",
      "{'accuracy': 0.7790724134860513, 'precision': 0.8941471454621966, 'recall': 0.4555280623866651, 'f1': 0.6035661236011576, 'roc_auc': 0.9462425647231006, 'log_loss': 2.8996173670369143}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 790/790 [01:37<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.34601320041508615\n",
      "\n",
      "Test metrics:\n",
      "{'accuracy': 0.7715116796770651, 'precision': 0.8751318843637899, 'recall': 0.4445546146425126, 'f1': 0.5896005117998294, 'roc_auc': 0.9224930834428118, 'log_loss': 3.375259546974777}\n",
      "\n",
      "Epoch [8 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches:  81%|████████  | 1910/2369 [13:47<03:47,  2.02it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    n_epochs=config['N_EPOCHS'],\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), f'{experiment_name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseContrastiveBERT(\n",
    "    bert_model=bert_model,\n",
    "    pooler=pooler,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(f'{experiment_name}.pth'))\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorize question1: 100%|██████████| 2369/2369 [01:50<00:00, 21.40it/s]\n",
      "vectorize question2: 100%|██████████| 2369/2369 [02:06<00:00, 18.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_metrics = compute_metrics_on_df_contrastive(\n",
    "    model=model,\n",
    "    df=df_train,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8075074946325569,\n",
       " 'precision': 0.8956345807366276,\n",
       " 'recall': 0.5417474340536147,\n",
       " 'f1': 0.6751270448233061,\n",
       " 'roc_auc': 0.9565895236466382,\n",
       " 'log_loss': 2.502801084654033}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorize question1: 100%|██████████| 790/790 [00:36<00:00, 21.77it/s]\n",
      "vectorize question2: 100%|██████████| 790/790 [00:42<00:00, 18.72it/s]\n"
     ]
    }
   ],
   "source": [
    "test_metrics = compute_metrics_on_df_contrastive(\n",
    "    model=model,\n",
    "    df=df_test,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    batch_size=config['BATCH_SIZE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7872923530517547,\n",
       " 'precision': 0.8616306186839819,\n",
       " 'recall': 0.5049576589130668,\n",
       " 'f1': 0.6367491763115655,\n",
       " 'roc_auc': 0.9230472721477609,\n",
       " 'log_loss': 3.2070163058813783}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = math.ceil(len(df_submission) / config['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorize question1:  48%|████▊     | 8800/18327 [07:07<07:55, 20.04it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1_emb = []\n",
    "for texts in tqdm(\n",
    "    chunks(df_submission['question1'].to_list(), n=config['BATCH_SIZE']),\n",
    "    total=length,\n",
    "    desc='vectorize question1',\n",
    "):\n",
    "    emb = model.vectorize(texts, tokenizer, tokenizer_kwargs)\n",
    "    q1_emb.append(emb)\n",
    "\n",
    "q2_emb = []\n",
    "for texts in tqdm(\n",
    "    chunks(df_submission['question2'].to_list(), n=config['BATCH_SIZE']),\n",
    "    total=length,\n",
    "    desc='vectorize question2',\n",
    "):\n",
    "    emb = model.vectorize(texts, tokenizer, tokenizer_kwargs)\n",
    "    q2_emb.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18327/18327 [00:01<00:00, 11053.29it/s]\n"
     ]
    }
   ],
   "source": [
    "y_score = []\n",
    "\n",
    "for i in trange(length):\n",
    "    with torch.no_grad():\n",
    "        y_score_batch = model.exponent_neg_manhattan_distance(q1_emb[i], q2_emb[i])\n",
    "        y_score_batch = y_score_batch.cpu().numpy()\n",
    "    y_score.append(y_score_batch)\n",
    "\n",
    "y_score = np.concatenate(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['is_duplicate'] = y_score\n",
    "df_submission['is_duplicate'].to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1457a1728d05db363c00391e3074737c9ebdc2935a146b6baa1e446523e7e6bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

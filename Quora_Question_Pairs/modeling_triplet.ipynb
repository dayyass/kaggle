{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset import TripletCollator, TripletDataset\n",
    "from metrics import compute_metrics_on_df\n",
    "from nn_modules.poolers import MeanPooler\n",
    "from nn_modules.triplet_models import SiameseTripletBERT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "from train_triplet import train\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from utils import chunks, set_global_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "config = {\n",
    "    'MODEL_NAME':         'distilroberta-base',\n",
    "    'BATCH_SIZE':         32,\n",
    "    'LEARNING_RATE':      1e-5,\n",
    "    'N_EPOCHS':           5,\n",
    "    'MARGIN':             2,\n",
    "    'N_NEGATIVE_SAMPLES': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "experiment_name = f\"MODEL_CONTRASTIVE_{config['MODEL_NAME']}_BATCH_{config['BATCH_SIZE']}_LR_{config['LEARNING_RATE']}_MARGIN_{config['MARGIN']}_N_NEGATIVE_SAMPLES_{config['N_NEGATIVE_SAMPLES']}\"\n",
    "\n",
    "writer = SummaryWriter(\n",
    "    log_dir=f\"runs/{experiment_name}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv('./data/test.csv', index_col='test_id')\n",
    "df_submission.fillna('', inplace=True)\n",
    "\n",
    "df_submission['question1'] = df_submission['question1'].str.lower()\n",
    "df_submission['question2'] = df_submission['question2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv', index_col='id')\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "df['question1'] = df['question1'].str.lower()\n",
    "df['question2'] = df['question2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=df['is_duplicate'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train size: {df_train.shape[0]}')\n",
    "print(f'Test size: {df_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_triplet = df_train[df_train['is_duplicate'] == 1]\n",
    "df_test_triplet = df_test[df_test['is_duplicate'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train triplet size: {df_train_triplet.shape[0]}')\n",
    "print(f'Test triplet size: {df_test_triplet.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(df=df_train_triplet, n_negative_samples=config['N_NEGATIVE_SAMPLES'])\n",
    "test_dataset = TripletDataset(df=df_test_triplet, n_negative_samples=config['N_NEGATIVE_SAMPLES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config['MODEL_NAME'])\n",
    "bert_model = AutoModel.from_pretrained(config['MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "    'return_tensors': 'pt',\n",
    "    'padding':        True,\n",
    "    'truncation':     True,\n",
    "    'max_length':     512,\n",
    "}\n",
    "\n",
    "collate_fn = TripletCollator(tokenizer, tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler = MeanPooler()\n",
    "\n",
    "model = SiameseTripletBERT(\n",
    "    bert_model=bert_model,\n",
    "    pooler=pooler,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['LEARNING_RATE'])\n",
    "criterion = torch.nn.TripletMarginLoss(margin=config['MARGIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    n_epochs=config['N_EPOCHS'],\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), f'{experiment_name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseTripletBERT(\n",
    "    bert_model=bert_model,\n",
    "    pooler=pooler,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(f'{experiment_name}.pth'))\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = compute_metrics_on_df(\n",
    "    model=model,\n",
    "    df=df_train,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = compute_metrics_on_df(\n",
    "    model=model,\n",
    "    df=df_test,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    batch_size=config['BATCH_SIZE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df_submission.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = math.ceil(len(df_submission) / config['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_emb = []\n",
    "for texts in tqdm(\n",
    "    chunks(df_submission['question1'].to_list(), n=config['BATCH_SIZE']),\n",
    "    total=length,\n",
    "    desc='vectorize question1',\n",
    "):\n",
    "    emb = model.vectorize(texts, tokenizer, tokenizer_kwargs)\n",
    "    q1_emb.append(emb)\n",
    "\n",
    "q2_emb = []\n",
    "for texts in tqdm(\n",
    "    chunks(df_submission['question2'].to_list(), n=config['BATCH_SIZE']),\n",
    "    total=length,\n",
    "    desc='vectorize question2',\n",
    "):\n",
    "    emb = model.vectorize(texts, tokenizer, tokenizer_kwargs)\n",
    "    q2_emb.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = []\n",
    "\n",
    "for i in trange(length):\n",
    "    y_score_batch = model.similarity(q1_emb[i], q2_emb[i]).cpu().numpy()\n",
    "    y_score.append(y_score_batch)\n",
    "\n",
    "y_score = np.concatenate(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['is_duplicate'] = y_score\n",
    "df_submission['is_duplicate'].to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1457a1728d05db363c00391e3074737c9ebdc2935a146b6baa1e446523e7e6bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
